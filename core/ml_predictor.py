"""
Robust ML Predictor module that fixes the critical model loading failures.

FIXES:
- NoneType scaler.transform() errors
- Proper model validation before usage
- Fallback mechanisms for failed predictions  
- Centralized model management
"""

import logging
import os
import joblib
import numpy as np
from typing import Dict, Tuple, Optional, Any
from dataclasses import dataclass

from config import (
    get_xgb_model_file, get_xgb_scaler_file, EXPECTED_COLUMNS,
    NEUTRAL_UPPER_THRESHOLD, NEUTRAL_LOWER_THRESHOLD
)


@dataclass
class ModelPrediction:
    """Structured prediction result"""
    symbol: str
    timeframe: str
    prediction: Optional[int]  # 0=SELL, 1=BUY, 2=NEUTRAL, None=FAILED
    confidence: float
    error: Optional[str] = None


class RobustMLPredictor:
    """
    Robust ML Predictor that handles model loading failures gracefully
    """
    
    def __init__(self, timeframes: list):
        self.timeframes = timeframes
        self.models = {}
        self.scalers = {}
        self.model_status = {}
        self._load_all_models()
    
    def _load_all_models(self):
        """Load all models with comprehensive validation"""
        logging.info("üîÑ Loading ML models with robust validation...")
        
        for tf in self.timeframes:
            success = self._load_model_for_timeframe(tf)
            self.model_status[tf] = success
            
        # Check if we have at least one working model
        working_models = sum(1 for status in self.model_status.values() if status)
        total_models = len(self.model_status)
        
        if working_models == 0:
            raise RuntimeError("‚ùå CRITICAL: No ML models loaded successfully. Bot cannot operate.")
        elif working_models < total_models:
            logging.warning(f"‚ö†Ô∏è Only {working_models}/{total_models} models loaded successfully")
        else:
            logging.info(f"‚úÖ All {working_models} ML models loaded successfully")
    
    def _load_model_for_timeframe(self, timeframe: str) -> bool:
        """Load model and scaler for a specific timeframe with validation"""
        try:
            model_file = get_xgb_model_file(timeframe)
            scaler_file = get_xgb_scaler_file(timeframe)
            
            # Check file existence
            if not os.path.exists(model_file):
                logging.error(f"‚ùå Model file not found for {timeframe}: {model_file}")
                return False
                
            if not os.path.exists(scaler_file):
                logging.error(f"‚ùå Scaler file not found for {timeframe}: {scaler_file}")
                return False
            
            # Load model and scaler
            model = joblib.load(model_file)
            scaler = joblib.load(scaler_file)
            
            # Validate model and scaler
            if model is None:
                logging.error(f"‚ùå Model loaded as None for {timeframe}")
                return False
                
            if scaler is None:
                logging.error(f"‚ùå Scaler loaded as None for {timeframe}")
                return False
                
            # Test prediction capability with dummy data
            try:
                dummy_features = self._create_dummy_features()
                dummy_scaled = scaler.transform(dummy_features.reshape(1, -1))
                dummy_pred = model.predict_proba(dummy_scaled)
                
                if dummy_pred is None or len(dummy_pred) == 0:
                    logging.error(f"‚ùå Model prediction test failed for {timeframe}")
                    return False
                    
            except Exception as test_error:
                logging.error(f"‚ùå Model validation test failed for {timeframe}: {test_error}")
                return False
            
            # If we get here, model is valid
            self.models[timeframe] = model
            self.scalers[timeframe] = scaler
            logging.info(f"‚úÖ Model loaded and validated for {timeframe}")
            return True
            
        except Exception as e:
            logging.error(f"‚ùå Failed to load model for {timeframe}: {e}")
            return False
    
    def _create_dummy_features(self) -> np.ndarray:
        """Create dummy features for model validation testing"""
        # FIXED: Match the exact temporal features count from create_temporal_features
        # Based on error: "expecting 66 features" - using actual count
        expected_features = 66  # Must match create_temporal_features actual output
        return np.random.random(expected_features)
    
    def predict_for_symbol(self, symbol: str, dataframes: Dict[str, Any], time_steps: int) -> Tuple[Optional[float], Optional[int], Dict[str, int]]:
        """
        Make robust predictions for a symbol across all timeframes
        
        Returns:
            ensemble_confidence, final_signal, individual_predictions
        """
        predictions = {}
        confidences = {}
        
        # Get predictions from all available models
        for tf, df in dataframes.items():
            if tf not in self.model_status or not self.model_status[tf]:
                logging.warning(f"‚ö†Ô∏è Skipping {symbol}[{tf}]: Model not available")
                continue
                
            try:
                pred_result = self._predict_single_timeframe(symbol, tf, df, time_steps)
                
                if pred_result.prediction is not None:
                    predictions[tf] = pred_result.prediction
                    confidences[tf] = pred_result.confidence
                else:
                    logging.warning(f"‚ö†Ô∏è Prediction failed for {symbol}[{tf}]: {pred_result.error}")
                    
            except Exception as e:
                logging.error(f"‚ùå Unexpected error predicting {symbol}[{tf}]: {e}")
                continue
        
        # If no predictions succeeded, return failure
        if not predictions:
            logging.error(f"‚ùå All predictions failed for {symbol}")
            return None, None, {}
        
        # Ensemble voting from successful predictions
        ensemble_confidence, final_signal = self._ensemble_vote(predictions, confidences)
        
        return ensemble_confidence, final_signal, predictions
    
    def _predict_single_timeframe(self, symbol: str, timeframe: str, df: Any, time_steps: int) -> ModelPrediction:
        """Make prediction for single timeframe with comprehensive error handling"""
        
        try:
            # Validate inputs
            if df is None or len(df) < time_steps:
                return ModelPrediction(
                    symbol=symbol, 
                    timeframe=timeframe, 
                    prediction=None,
                    confidence=0.0,
                    error=f"Insufficient data: {len(df) if df is not None else 0} < {time_steps}"
                )
            
            # Verify expected columns
            if not set(df.columns) >= set(EXPECTED_COLUMNS):
                missing_cols = set(EXPECTED_COLUMNS) - set(df.columns)
                return ModelPrediction(
                    symbol=symbol,
                    timeframe=timeframe,
                    prediction=None,
                    confidence=0.0,
                    error=f"Missing columns: {missing_cols}"
                )
            
            # Prepare data - using simplified approach for now
            df_ordered = df[EXPECTED_COLUMNS]
            data = df_ordered.values
            
            # Clean data
            data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)
            
            if len(data) < time_steps:
                return ModelPrediction(
                    symbol=symbol,
                    timeframe=timeframe,
                    prediction=None,
                    confidence=0.0,
                    error=f"Data length {len(data)} < time_steps {time_steps}"
                )
            
            # Get sequence
            sequence = data[-time_steps:]
            
            # Create temporal features (simplified version)
            temporal_features = self._create_temporal_features_safe(sequence)
            
            # Get model and scaler (already validated)
            model = self.models[timeframe]
            scaler = self.scalers[timeframe]
            
            # Scale features
            X_scaled = scaler.transform(temporal_features.reshape(1, -1))
            
            # Predict
            probs = model.predict_proba(X_scaled)[0]
            prediction = np.argmax(probs)
            confidence = np.max(probs)
            
            return ModelPrediction(
                symbol=symbol,
                timeframe=timeframe,
                prediction=int(prediction),
                confidence=float(confidence)
            )
            
        except Exception as e:
            return ModelPrediction(
                symbol=symbol,
                timeframe=timeframe,
                prediction=None,
                confidence=0.0,
                error=str(e)
            )
    
    def _create_temporal_features_safe(self, sequence: np.ndarray) -> np.ndarray:
        """
        Create temporal features - MUST MATCH EXACTLY trainer.py create_temporal_features()
        
        CRITICAL FIX: Use the exact same logic as training to ensure feature count match
        """
        try:
            features = []
            
            # 1. CURRENT STATE: Most recent values (most important for trading) 
            features.extend(sequence[-1])  # Latest candle: 34 features
            
            # 2. TREND: Simple trend indicators (price momentum)  
            if len(sequence) > 1:
                # Price change from first to last
                price_change = (sequence[-1] - sequence[0]) / (np.abs(sequence[0]) + 1e-8)
                features.extend(price_change)  # Trend direction: 34 features
            else:
                features.extend(np.zeros(sequence.shape[1]))
            
            # TOTAL: ~68 features (34 current + 34 trend) - SAME AS TRAINING
            
            # Clean and validate
            features = np.array(features, dtype=np.float64)
            features = np.nan_to_num(features, nan=0.0, posinf=1e6, neginf=-1e6)
            
            return features.flatten()
            
        except Exception as e:
            logging.error(f"Error creating temporal features: {e}")
            # Emergency fallback: just use last timestep
            return np.nan_to_num(sequence[-1].flatten(), nan=0.0, posinf=0.0, neginf=0.0)
    
    def _ensemble_vote(self, predictions: Dict[str, int], confidences: Dict[str, float]) -> Tuple[float, int]:
        """
        Simple majority voting ensemble with confidence weighting
        """
        if not predictions:
            return 0.0, 2  # No predictions -> NEUTRAL
        
        # Count votes
        vote_counts = {}
        weighted_votes = {}
        
        for tf, pred in predictions.items():
            confidence = confidences.get(tf, 0.5)
            
            # Count votes
            vote_counts[pred] = vote_counts.get(pred, 0) + 1
            
            # Weighted votes
            weighted_votes[pred] = weighted_votes.get(pred, 0.0) + confidence
        
        # Get majority vote
        majority_vote = max(vote_counts.items(), key=lambda x: x[1])[0]
        
        # Calculate ensemble confidence
        total_confidence = sum(confidences.values())
        majority_confidence = weighted_votes.get(majority_vote, 0.0)
        ensemble_confidence = majority_confidence / total_confidence if total_confidence > 0 else 0.0
        
        return ensemble_confidence, majority_vote
    
    def get_model_status(self) -> Dict[str, bool]:
        """Get status of all models"""
        return self.model_status.copy()
    
    def is_operational(self) -> bool:
        """Check if predictor has at least one working model"""
        return any(self.model_status.values())


# Backward compatibility function for existing code
def predict_signal_ensemble(dataframes, xgb_models, xgb_scalers, symbol, time_steps):
    """
    Backward compatibility wrapper - but with robust error handling
    """
    try:
        # Check if models/scalers are actually loaded
        working_timeframes = []
        for tf in dataframes.keys():
            if (tf in xgb_models and tf in xgb_scalers and 
                xgb_models[tf] is not None and xgb_scalers[tf] is not None):
                working_timeframes.append(tf)
        
        if not working_timeframes:
            logging.error(f"‚ùå No working models available for {symbol}")
            return None, None, {}
        
        # Use only working timeframes
        filtered_dataframes = {tf: dataframes[tf] for tf in working_timeframes}
        
        # Create temporary predictor instance
        predictor = RobustMLPredictor(working_timeframes)
        predictor.models = {tf: xgb_models[tf] for tf in working_timeframes}
        predictor.scalers = {tf: xgb_scalers[tf] for tf in working_timeframes}
        predictor.model_status = {tf: True for tf in working_timeframes}
        
        # Make prediction
        return predictor.predict_for_symbol(symbol, filtered_dataframes, time_steps)
        
    except Exception as e:
        logging.error(f"‚ùå Robust prediction failed for {symbol}: {e}")
        return None, None, {}
